{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ky1HBDHSQ7Pe",
        "outputId": "2863d363-3ee2-49e4-f6bb-a2f896a342a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers-interpret==0.6.0 in /usr/local/lib/python3.8/dist-packages (0.6.0)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from transformers-interpret==0.6.0) (4.25.1)\n",
            "Requirement already satisfied: captum>=0.3.1 in /usr/local/lib/python3.8/dist-packages (from transformers-interpret==0.6.0) (0.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from captum>=0.3.1->transformers-interpret==0.6.0) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.8/dist-packages (from captum>=0.3.1->transformers-interpret==0.6.0) (1.13.0+cu116)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from captum>=0.3.1->transformers-interpret==0.6.0) (3.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.6->captum>=0.3.1->transformers-interpret==0.6.0) (4.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.0->transformers-interpret==0.6.0) (0.11.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.0->transformers-interpret==0.6.0) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.0->transformers-interpret==0.6.0) (0.13.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.0->transformers-interpret==0.6.0) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.0->transformers-interpret==0.6.0) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.0->transformers-interpret==0.6.0) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.0->transformers-interpret==0.6.0) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.0->transformers-interpret==0.6.0) (3.8.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers>=3.0.0->transformers-interpret==0.6.0) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->captum>=0.3.1->transformers-interpret==0.6.0) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->captum>=0.3.1->transformers-interpret==0.6.0) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->captum>=0.3.1->transformers-interpret==0.6.0) (1.4.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->captum>=0.3.1->transformers-interpret==0.6.0) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=3.0.0->transformers-interpret==0.6.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=3.0.0->transformers-interpret==0.6.0) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=3.0.0->transformers-interpret==0.6.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=3.0.0->transformers-interpret==0.6.0) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.8.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.11.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tweet-preprocessor in /usr/local/lib/python3.8/dist-packages (0.6.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: emoji==0.6.0 in /usr/local/lib/python3.8/dist-packages (0.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers-interpret==0.6.0\n",
        "!pip install datasets\n",
        "!pip install tweet-preprocessor\n",
        "!pip install emoji==0.6.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngLb0Pxie71g",
        "outputId": "7729863a-b263-4ccb-9a52-889bc4e639cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# connect to gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UQvSSxsRF9W",
        "outputId": "0d809b1f-2bfe-44e1-ea22-470a54239365"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import datasets\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "import preprocessor as p\n",
        "import torch.nn as nn\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from datasets import Dataset, load_metric, load_dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import get_scheduler, AdamW\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from transformers import AutoTokenizer,AutoModelForSequenceClassification, DataCollatorWithPadding,BartForConditionalGeneration\n",
        "from transformers_interpret import MultiLabelClassificationExplainer,SequenceClassificationExplainer\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GhJOXaN6r9z"
      },
      "outputs": [],
      "source": [
        "dir_path = '/content/gdrive/MyDrive/PhD/Explainability_Project_2022/RV_models/BERT/Final_notebook/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PO2MA8Bo2UBL"
      },
      "source": [
        "The prediction labels are: \n",
        "\n",
        "*   0 = True\n",
        "*   1 = False\n",
        "* 2 = *Unverified*\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veKfKdZOdn8a"
      },
      "source": [
        "# 1. Construct BERT model for rumour verification\n",
        "\n",
        "We train a BERT model using the source tweet (claim of the rumour) and first-level replies (referred as replies for convenience) as input. For the purpose of this study we ignore replies posted deeper in the thread e.g. replies of replies. \n",
        "\n",
        "Training instances are of the form: *source tweet [SEP] reply*. Hence, for a thread with *n* replies, we generate *n* training instances.\n",
        "\n",
        "Note that this enables us to use all the information in the replies and avoid out-of-memory issues which occur in the rationale generation for Section 2. The trade-off is sacrificing some faithfulness as the claim is predicted *n* labels which are aggregated to form a final label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gYmW9qhezchf"
      },
      "outputs": [],
      "source": [
        "#Preprocess function for tweets\n",
        "\n",
        "p.set_options(p.OPT.EMOJI, p.OPT.SMILEY)\n",
        "def preprocess_tweet(tweet):\n",
        "    tweet = tweet.lower()\n",
        "    tweet = tweet.replace('\\n','').replace('\\t','')\n",
        "    tweet = re.sub(r'http\\S+', 'URL', tweet)\n",
        "    tweet = re.sub(r'@\\w+', 'MENTION', tweet)\n",
        "    tweet = p.clean(tweet)\n",
        " \n",
        "    return tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLnt58OwegJ3"
      },
      "outputs": [],
      "source": [
        "def prep_data(fold, cvfolds):  \n",
        "    # We only use the original (unshuffled) data for testing\n",
        "    test = {}\n",
        "    test['data'] = []\n",
        "    test['data'] = cvfolds[fold]\n",
        "    \n",
        "    savepath1 = dir_path + \"test_\" + fold + \".json\"\n",
        "    with open(savepath1, 'w+') as f:\n",
        "        json.dump(test, f)    \n",
        "    testset = load_dataset('json', data_files=savepath1, field='data')\n",
        "    \n",
        "    train = {}\n",
        "    train['data'] = []\n",
        "    for fo in list(cvfolds.keys()): \n",
        "        if fo!=fold:\n",
        "            train['data'].extend(cvfolds[fo])\n",
        "    savepath2 = dir_path + \"train_\" + fold + \".json\"\n",
        "    with open(savepath2, 'w+') as f:\n",
        "        json.dump(train, f)\n",
        "    trainset = load_dataset('json', data_files=savepath2, field='data')\n",
        "    \n",
        "    return testset, trainset    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inSqkFcP3EPz"
      },
      "outputs": [],
      "source": [
        "checkpoint = \"vinai/bertweet-large\" # \"bert-base-uncased\" # \"cardiffnlp/twitter-roberta-base\" #\"roberta-large\" #\"bert-base-uncased\" #\"digitalepidemiologylab/covid-twitter-bert-v2\" #\"cardiffnlp/twitter-roberta-base\" # \"roberta-large\" # \"bert-base-uncased\" # # #  # # # # #\" # # #\"digitalepidemiologylab/covid-twitter-bert-v2\" #\"roberta-large\"#\"bert-base-uncased\" #\"bert-large-cased\" #\"roberta-large\" #\"bert-base-uncased\" #\"bert-large-cased\" # #\"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "bs = 4\n",
        "\n",
        "def tokenize_function(example):   \n",
        "    return tokenizer(example['pp_source_reply'], truncation=True,max_length=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4MPSxUU3S6K"
      },
      "outputs": [],
      "source": [
        "def reset_weights(m):\n",
        "  '''\n",
        "    Try resetting model weights to avoid\n",
        "    weight leakage.\n",
        "  '''\n",
        "  for layer in m.children():\n",
        "   if hasattr(layer, 'reset_parameters'):\n",
        "    print(f'Reset trainable parameters of layer = {layer}')\n",
        "    layer.reset_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNUtxxyY4j2b"
      },
      "source": [
        "Note that the model is trained on a leave-one-event out cross validation setting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOQzIuVk3ZcD"
      },
      "outputs": [],
      "source": [
        "#Load data\n",
        "\n",
        "with open(os.path.join(dir_path, 'pheme_reply_entries.json'),'r') as f:\n",
        "    cvfolds = json.load(f)\n",
        "\n",
        "for fold in list(cvfolds.keys()):\n",
        " \n",
        "    testset, trainset = prep_data(fold, cvfolds)\n",
        "    testset_ids = list(testset['train']['idx'])\n",
        "    \n",
        "    print (len(testset_ids))\n",
        "  \n",
        "    tokenized_datasets = trainset.map(tokenize_function, batched=True)\n",
        "    tokenized_datasets = tokenized_datasets.remove_columns([\"sentence1\", \"idx\",\"source_reply\",\"pp_source_reply\"])\n",
        "    tokenized_datasets.set_format(\"torch\")\n",
        "    print(tokenized_datasets)\n",
        "    \n",
        "    tokenized_testset = testset.map(tokenize_function, batched=True)\n",
        "    tokenized_testset = tokenized_testset.remove_columns([\"sentence1\", \"idx\",\"source_reply\",\"pp_source_reply\"])\n",
        "    tokenized_testset.set_format(\"torch\",columns=['input_ids', 'attention_mask', 'labels']) #'token_type_ids', for bert?\n",
        "    \n",
        "    train_dataloader = DataLoader(\n",
        "        tokenized_datasets[\"train\"], shuffle=True, batch_size=bs, collate_fn=data_collator)\n",
        "   \n",
        "    eval_dataloader = DataLoader(\n",
        "        tokenized_testset[\"train\"], batch_size=bs, collate_fn=data_collator)\n",
        "    \n",
        "    model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3)\n",
        "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "    model.to(device)\n",
        "    \n",
        "    optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "    \n",
        "    num_epochs = 10\n",
        "    num_training_steps = num_epochs * len(train_dataloader)\n",
        "    lr_scheduler = get_scheduler(\"linear\",optimizer=optimizer,num_warmup_steps=0,num_training_steps=num_training_steps)\n",
        "    #print(num_training_steps)\n",
        "\n",
        "    progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        for batch in train_dataloader:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(**batch)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            lr_scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "            progress_bar.update(1)\n",
        "            \n",
        "    # Save state dictionary    \n",
        "    model_path = dir_path'+'model_{}'.format(fold)\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    \n",
        "\n",
        "    all_test_predictions = []\n",
        "    all_test_labels = []\n",
        "    metric = load_metric(\"accuracy\", \"f1\")\n",
        "    model.eval()\n",
        "    for batch in eval_dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch)\n",
        "\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "        all_test_predictions.extend(predictions)\n",
        "        all_test_labels.extend(batch['labels'])\n",
        "        metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "    metric.compute()\n",
        "    print(fold,all_test_predictions)\n",
        "    all_test_predictions = [int(i) for i in all_test_predictions]\n",
        "    all_test_labels = [int(i) for i in all_test_labels]\n",
        "    \n",
        "    print(accuracy_score (all_test_labels, all_test_predictions))\n",
        "    print(f1_score(all_test_labels, all_test_predictions, average='macro'))\n",
        "    \n",
        "    model.apply(reset_weights) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JQ_jmYS1OlT"
      },
      "source": [
        "# 2. Apply Rationale-based explainer on BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWMGWv3X3DTT"
      },
      "source": [
        "Load Model trained for 'sydneysiege\" using the state dictionary. \n",
        "This is found in the workspace folder.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiL4P9KM3Dzx",
        "outputId": "425e0cb7-ddac-46dc-ea64-c9e3c82e18b2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at vinai/bertweet-large were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-large and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "  checkpoint = \"vinai/bertweet-large\" # \"bert-base-uncased\" # \"cardiffnlp/twitter-roberta-base\" #\"roberta-large\" #\"bert-base-uncased\" #\"digitalepidemiologylab/covid-twitter-bert-v2\" #\"cardiffnlp/twitter-roberta-base\" # \"roberta-large\" # \"bert-base-uncased\" # # #  # # # # #\" # # #\"digitalepidemiologylab/covid-twitter-bert-v2\" #\"roberta-large\"#\"bert-base-uncased\" #\"bert-large-cased\" #\"roberta-large\" #\"bert-base-uncased\" #\"bert-large-cased\" # #\"bert-base-uncased\"\n",
        "  tokenizer = AutoTokenizer.from_pretrained(checkpoint,truncation=True,max_length=512)   \n",
        "\n",
        "  #Load the trained BERT model\n",
        "  saved_model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3)\n",
        "  device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "  saved_model.load_state_dict(torch.load(dir_path + \"model_sydneysiege\",map_location=torch.device('cpu')))\n",
        "  #saved_model.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cX0_j4sVD1t9"
      },
      "source": [
        "We use a toy test set which contains 13 threads from the sydney-siege fold. \n",
        "Let's run the explainer model on a a particular example: take the first reply in the first twitter thread of the test sample. Run BERT on the concatenation between the source tweet and the reply."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgJdBVDDbKQA",
        "outputId": "16cc6d4e-7132-4f91-be38-ad15ba550a6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13\n",
            "Trial run for the explainer\n",
            "{'replies1': ['@newscomauHQ I hope this is true', '@newscomauHQ lets hope they are ok.', '@newscomauHQ hope they are safe', 'BREAKING: Hostages are running out of the cafe #sydneysiege v @newscomauHQ', 'OMG is this true “@newscomauHQ: BREAKING: Hostages are running out of the cafe #sydneysiege”', '@newscomauHQ If this is true, what great news.  Is incident over?', '“@newscomauHQ: BREAKING: Hostages are running out of the cafe #sydneysiege” please let this be true', '“@newscomauHQ: BREAKING: Hostages are running out of the cafe #sydneysiege” I hope this is true', '@newscomauHQ Please let this be true!', '@newscomauHQ @mirandadevine if this is true, I fear this could turn very nasty very quickly as the remaining ones may be abused by terrorist', '@newscomauHQ how bout keeping that quiet @neontaster'], 'idx': 544350480780914688, 'labels': 0, 'sentence1': 'BREAKING: Hostages are running out of the cafe #sydneysiege'}\n",
            "Claim:  BREAKING: Hostages are running out of the cafe #sydneysiege\n",
            "Reply:  @newscomauHQ I hope this is true\n"
          ]
        }
      ],
      "source": [
        " with open(dir_path +\"explainer_input_test.json\",'r') as f:\n",
        "    test = json.load(f)\n",
        "\n",
        "print(len(test['sydneysiege']))\n",
        "\n",
        "print('Trial run for the explainer')\n",
        "\n",
        "instance = test['sydneysiege'][0]\n",
        "print(instance)\n",
        "print('Claim: ', instance['sentence1'])\n",
        "print('Reply: ', instance['replies1'][0])\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use the transformers-interpret library which relies on Integrated Gradients as laid out in the paper Axiomatic Attributions for Deep Networks (Sundararajan et al.,2017 https://arxiv.org/pdf/1703.01365.pdf). This method will ouput an attribution score for each token in the tokenized text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "vAhvjYXZSowX"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Find which replies contributed for the prediction\n",
        "cls_explainer = MultiLabelClassificationExplainer(saved_model, tokenizer)\n",
        "mini_text_input = instance['sentence1'] + ' [SEP] ' + instance['replies1'][0]\n",
        "mini_text_input = preprocess_tweet(mini_text_input)\n",
        "word_attributions = cls_explainer(mini_text_input,internal_batch_size=2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxDGD2xde6QU",
        "outputId": "e1034de1-0eab-48ba-9de3-0b85d95fe128"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'LABEL_0': [('<s>', 0.0), ('breaking', 0.02013541385752795), (':', -0.008238418946795948), ('hostages', 0.059403423359093446), ('are', 0.030279127155955345), ('running', -0.368238855365563), ('out', -0.10688875418590367), ('of', 0.15389767020172143), ('the', 0.23447527356990894), ('cafe', 0.21108824998935136), ('#', 0.12382871183519698), ('sy', 0.6533669436296611), ('d', -0.18311717640404573), ('neys', 0.16205672042505898), ('iege', 0.10915219608127644), ('[', -0.21827548559888135), ('se', 0.09449431965693357), ('p', 0.01769258883053469), (']', 0.08033574402856011), ('M', 0.3725545238239933), ('ENTION', 0.045396408027896365), ('i', -0.030684950591865295), ('hope', -0.0019691545662734815), ('this', -0.003057696333650379), ('is', -0.04093257733950469), ('true', -0.06384394519442635), ('</s>', 0.0)], 'LABEL_1': [('<s>', 0.0), ('breaking', 0.12755099058708746), (':', -0.0006147288380746749), ('hostages', -0.028348606078918894), ('are', -0.11490996673405893), ('running', -0.10193128329710545), ('out', -0.09190818554181523), ('of', 0.01438803370527067), ('the', 0.20045245946051213), ('cafe', 0.050452635901356825), ('#', -0.28686935484690157), ('sy', -0.8884578405479613), ('d', -0.053974799468788484), ('neys', 0.01139593308791298), ('iege', 0.001987871696091771), ('[', 0.04460637159801951), ('se', 0.077816087952436), ('p', 0.08074165215605222), (']', 0.023222659720112025), ('M', 0.12063844285634867), ('ENTION', -0.002907420889158949), ('i', -0.011190157142790685), ('hope', 0.01421195721622172), ('this', 0.041704026772230805), ('is', 0.019354203068697614), ('true', 0.03386022330221182), ('</s>', 0.0)], 'LABEL_2': [('<s>', 0.0), ('breaking', -0.05478534452628623), (':', 0.009145432438145976), ('hostages', -0.05750862818439478), ('are', -0.0034641955702878137), ('running', 0.42793781792569663), ('out', 0.14025311895883302), ('of', -0.1715884134908654), ('the', -0.30736563814523143), ('cafe', -0.2432567601200999), ('#', -0.06127046357879238), ('sy', -0.4841487838136809), ('d', 0.21364978871336268), ('neys', -0.1797191018304455), ('iege', -0.11958512301920221), ('[', 0.22663789514255617), ('se', -0.1231059159172778), ('p', -0.04007613264584877), (']', -0.09361318405184055), ('M', -0.437458798562404), ('ENTION', -0.048774541033241414), ('i', 0.03635339074282419), ('hope', -0.001508648290629542), ('this', -0.0073950594194065146), ('is', 0.03967319645358035), ('true', 0.060934545172740336), ('</s>', 0.0)]}\n"
          ]
        }
      ],
      "source": [
        "print(word_attributions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "4C6qqC4PS62Z",
        "outputId": "bbfe5e65-a375-435c-8c65-a8d0a80e4bba"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>n/a</b></text></td><td><text style=\"padding-right:2em\"><b> (0.62)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_0</b></text></td><td><text style=\"padding-right:2em\"><b>1.34</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #s                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> breaking                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> :                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hostages                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> are                    </font></mark><mark style=\"background-color: hsl(0, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> running                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> out                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> cafe                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #                    </font></mark><mark style=\"background-color: hsl(120, 75%, 68%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> sy                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> d                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> neys                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> iege                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> se                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> p                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> M                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ENTION                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> i                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hope                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> this                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> true                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>n/a</b></text></td><td><text style=\"padding-right:2em\"><b> (0.00)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1</b></text></td><td><text style=\"padding-right:2em\"><b>-0.72</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #s                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> breaking                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> :                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hostages                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> are                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> running                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> out                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> cafe                    </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #                    </font></mark><mark style=\"background-color: hsl(0, 75%, 65%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> sy                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> d                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> neys                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> iege                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> se                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> p                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> M                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ENTION                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> i                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hope                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> this                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> true                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>n/a</b></text></td><td><text style=\"padding-right:2em\"><b> (0.38)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_2</b></text></td><td><text style=\"padding-right:2em\"><b>-1.28</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #s                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> breaking                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> :                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hostages                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> are                    </font></mark><mark style=\"background-color: hsl(120, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> running                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> out                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> cafe                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #                    </font></mark><mark style=\"background-color: hsl(0, 75%, 81%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> sy                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> d                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> neys                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> iege                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> se                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> p                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> M                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ENTION                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> i                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hope                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> this                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> true                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark></td><tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>n/a</th><th>Prediction Score</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>n/a</b></text></td><td><text style=\"padding-right:2em\"><b> (0.62)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_0</b></text></td><td><text style=\"padding-right:2em\"><b>1.34</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #s                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> breaking                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> :                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hostages                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> are                    </font></mark><mark style=\"background-color: hsl(0, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> running                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> out                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> cafe                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #                    </font></mark><mark style=\"background-color: hsl(120, 75%, 68%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> sy                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> d                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> neys                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> iege                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> se                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> p                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> M                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ENTION                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> i                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hope                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> this                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> true                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>n/a</b></text></td><td><text style=\"padding-right:2em\"><b> (0.00)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1</b></text></td><td><text style=\"padding-right:2em\"><b>-0.72</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #s                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> breaking                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> :                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hostages                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> are                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> running                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> out                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> cafe                    </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #                    </font></mark><mark style=\"background-color: hsl(0, 75%, 65%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> sy                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> d                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> neys                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> iege                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> se                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> p                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> M                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ENTION                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> i                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hope                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> this                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> true                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>n/a</b></text></td><td><text style=\"padding-right:2em\"><b> (0.38)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_2</b></text></td><td><text style=\"padding-right:2em\"><b>-1.28</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #s                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> breaking                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> :                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hostages                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> are                    </font></mark><mark style=\"background-color: hsl(120, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> running                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> out                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> cafe                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #                    </font></mark><mark style=\"background-color: hsl(0, 75%, 81%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> sy                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> d                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> neys                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> iege                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> se                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> p                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> M                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ENTION                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> i                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hope                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> this                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> true                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark></td><tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cls_explainer.visualize(\"multilabel_viz.html\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnzN-19zN7lO"
      },
      "source": [
        "As seen in the visualisation above, the input's final attribution score is the sum of all individual attribution tokens. This is the highest for LABEL_0 which is also the predicted label for this instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuHWuYVomUi0",
        "outputId": "03ce2f2a-f68c-4335-af1d-bbafedc3b07a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted label  LABEL_0\n",
            "Gold Standard:  LABEL_0\n"
          ]
        }
      ],
      "source": [
        "gold_label = 'LABEL_' + str(instance['labels'])\n",
        "predicted_label = cls_explainer.predicted_class_name\n",
        "print(\"Predicted label \",predicted_label)\n",
        "print(\"Gold Standard: \", gold_label)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2s2R4d6NtYk"
      },
      "source": [
        "However, we notice that different rationales (subsets of the input) may support other labels and thus contribute negatively to the prediction. \n",
        "In our case, we are interested to check which label the tokens correponding to the reply support the most (reply = rationale). We use the separator [SEP] to indentify the span of the reply text from the claim text.\n",
        "\n",
        "For this example, we find that the reply \"I hope this is true\" will contribute positively to the overall prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94fjLbIjlUUW",
        "outputId": "253e8282-79e3-4c1c-fdc4-c957b2d30e59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label supported by the reply:  LABEL_0\n"
          ]
        }
      ],
      "source": [
        "# Indentify which label the reply contributes too the most.\n",
        "\n",
        "max_score = -1000\n",
        "supporting_label = ''\n",
        "start = 0\n",
        "for label in word_attributions.keys():\n",
        "    #Find position of separator token\n",
        "    for i,x in enumerate(word_attributions[label]):\n",
        "      if ']' in x[0] and i>1 and 'p' in word_attributions[label][i-1] and 'se' in word_attributions[label][i-2]:\n",
        "        start = i\n",
        "        break\n",
        "    #Check contribution score of the reply's specific location\n",
        "    reply_contribution = sum([word[1] for word in word_attributions[label][start+1:]])\n",
        "    if reply_contribution>max_score:\n",
        "        max_score = reply_contribution\n",
        "        supporting_label = label\n",
        "\n",
        "print('Label supported by the reply: ', supporting_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwn4ZnICgQJs"
      },
      "source": [
        "Now apply this step to all replies in the thread. This process creates a partition of the replies with respect to each supported label. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--PUSkCm3wON",
        "outputId": "41393102-c72c-423c-b33e-7b014af79b94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LABEL_0\n",
            "LABEL_0\n",
            "LABEL_0\n",
            "LABEL_0\n",
            "LABEL_0\n",
            "LABEL_0\n",
            "LABEL_0\n",
            "LABEL_0\n",
            "LABEL_0\n",
            "LABEL_0\n",
            "LABEL_0\n"
          ]
        }
      ],
      "source": [
        "#Now apply this step to all replies in the thread. We will find a partition of the replies wrt to each supported label\n",
        "\n",
        "cls_explainer = MultiLabelClassificationExplainer(saved_model, tokenizer)\n",
        "contributions_label = {'LABEL_0':[],'LABEL_1':[],'LABEL_2':[]}\n",
        "predicted_labels = []\n",
        "\n",
        "for reply in instance['replies1']:\n",
        "\n",
        "  mini_text_input = instance['sentence1'] + ' [SEP] ' + reply\n",
        "  mini_text_input = preprocess_tweet(mini_text_input)\n",
        "  cls_explainer = MultiLabelClassificationExplainer(saved_model, tokenizer)\n",
        "  word_attributions = cls_explainer(mini_text_input,internal_batch_size=2)\n",
        "  \n",
        "  # For each source+reply, the model will predict a label. This might not be a very good indicator of reply support since the source tweet dictates the annotation\n",
        "  predicted_label = cls_explainer.predicted_class_name\n",
        "  predicted_labels.append(predicted_label)\n",
        "  print(predicted_label)\n",
        "    \n",
        "  #___We want to find the label that this reply contributes too the most___\n",
        "  max_score = -1000\n",
        "  supporting_label = ''\n",
        "\n",
        "  for label in contributions_label.keys():\n",
        "      #Find position of separator token\n",
        "      for i,x in enumerate(word_attributions[label]):\n",
        "        if ']' in x[0] and i>1 and 'p' in word_attributions[label][i-1] and 'se' in word_attributions[label][i-2]:\n",
        "          start = i\n",
        "          break\n",
        "      #Check contribution score of the reply's specific location\n",
        "      reply_contribution = sum([word[1] for word in word_attributions[label][start+1:]])\n",
        "      if reply_contribution>max_score:\n",
        "          max_score = reply_contribution\n",
        "          supporting_label = label\n",
        "          \n",
        "  contributions_label[supporting_label].append({'text':reply,'word_attr':word_attributions})\n",
        "\n",
        "dict_to_save = {'replies':contributions_label, 'predicted_labels':predicted_labels,'source':instance['sentence1'],'gold_label':gold_label}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WlkOfmV9NbA"
      },
      "source": [
        "As calculating integrated gradients occurs over several steps (default 50) and all replies within the thread, the construction of the word attribution dictionaries can be quite long depending on the computing resources used. \n",
        "Files containing the explainer outputs are are provided in .json format in the folder *explainer_output* for each thread in the toy test set. These dictionaries are organised as:\n",
        "\n",
        "\n",
        "\n",
        "*   'replies': contains a dictionary of reply contributions for each label\n",
        "  \n",
        "*   'predicted labels': contains the predicted labels for each (source, reply) pair in the thread. Note that most predicted labels are consistent across all replies.\n",
        "*   'source': text of source (equivalent to rumour claim)\n",
        "*   'gold_label': the veracity of the source claim\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQoAJ_CPdaMI"
      },
      "source": [
        "# 3. Use scored rationales to create explanation-summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "RXEo3CGjsx1h"
      },
      "outputs": [],
      "source": [
        "#Load summarisation model\n",
        "\n",
        "model_name_ft = '/content/gdrive/MyDrive/PhD/Code/mos_workspace/BART_model'\n",
        "model_ft = BartForConditionalGeneration.from_pretrained(model_name_ft)\n",
        "tokenizer_ft = AutoTokenizer.from_pretrained(model_name_ft)\n",
        "\n",
        "\n",
        "def bart_ft(text,max_length,min_length):\n",
        "    inputs = tokenizer_ft.encode(text, return_tensors=\"pt\", max_length=1024)\n",
        "    outputs = model_ft.generate(inputs, max_length=max_length, min_length=min_length, length_penalty=2.0, num_beams=4, early_stopping=True,no_repeat_ngram_size=4)\n",
        "\n",
        "    summary = tokenizer_ft.decode(outputs[0],skip_special_tokens=True)\n",
        "    return summary\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0svychHje1o"
      },
      "source": [
        "## Summarise content of Twitter thread which supports the predicted label.\n",
        "\n",
        "From the previous step, we have indentified the replies supporting the prediction. Use the concatenation of the claim text (for context) and these replies as the input for the summarisation step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "flwFvXFWpqZp"
      },
      "outputs": [],
      "source": [
        "# Heuristic to use for determining the aggregated predicted label of the Twitter thread: We choose the most frequent label. \n",
        "from collections import Counter\n",
        "\n",
        "def most_common(mylist):\n",
        "    data = Counter(mylist)\n",
        "    return data.most_common(1)[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oQ01kexv0Zi"
      },
      "outputs": [],
      "source": [
        "# Run this cell if you want to obtain the explanation dictionary dict_to_save from the previous section. \n",
        "with open(dir_path + 'explainer_output/544350480780914688.json','r') as f:\n",
        "  dict_to_save2 = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZENlz-9xKUP",
        "outputId": "512733ca-76bb-40da-8556-0674301c8a0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input for Summarisation:  breaking: hostages are running out of the cafe #sydneysiege MENTION i hope this is true MENTION lets hope they are ok. MENTION hope they are safe breaking: hostages are running out of the cafe #sydneysiege v MENTION omg is this true MENTION: breaking: hostages are running out of the cafe #sydneysiege MENTION if this is true, what great news. is incident over? MENTION: breaking: hostages are running out of the cafe #sydneysiege please let this be true MENTION: breaking: hostages are running out of the cafe #sydneysiege i hope this is true MENTION please let this be true! MENTION how bout keeping that quiet MENTION\n"
          ]
        }
      ],
      "source": [
        "#Preprocess the summarisation input\n",
        "\n",
        "text = [dict_to_save['source']]\n",
        "text.extend([x['text'] for x in dict_to_save['replies'][predicted_label]])\n",
        "text = ' '.join(text)\n",
        "text = preprocess_tweet(text)\n",
        "print('Input for Summarisation: ', text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPU1wYf3lwPM",
        "outputId": "69ba66ff-24ae-412f-e004-8e360a4ecc02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " hostages are reportedly running out of the Sydney siege cafe The majority are hoping that this is true and are concerned for the safety of the hostages inside.\n"
          ]
        }
      ],
      "source": [
        "print(bart_ft(text,50,25))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNKU2kJL7_O5"
      },
      "source": [
        "The summary successfully explains why the claim is predicted to be true as the majority of users express hope for the good news regarding the escape of some hostages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cXge8Iqm1m6"
      },
      "source": [
        "## Summarise content of Twitter thread which supports the gold standard.\n",
        "\n",
        "In the cases where the model makes an incorrect prediction, we can choose to provide a justification for the correct answer. \n",
        "\n",
        "We select an example of a thread (found in *explainer_output/544338575240609792.json*) where a false rumour is predicted as true. Despite the incorrect final judgement of the RV step, the explainer model correctly uncovers the replies which support the gold standard. \n",
        "\n",
        "This is in line with published work (Ma et al, ACL 2017; Li et al, EMNLP 2019; Bian et al,AAAI 2020) that found user interactions valuable for determining the veracity of rumours on social media."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rN6bgDZnRbc",
        "outputId": "635804dd-82c8-428d-b5d1-655ecdeac7e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Claim:  #BREAKING: Flag w/ Islamic writing held up to window of #Sydney cafe. Police say up to 50 hostages. #Australia PM convenes security team.\n",
            "Gold standard:  LABEL_1\n",
            "Predicted_label:  LABEL_0\n",
            "#of replies supporting  LABEL_0 : 1\n",
            "#of replies supporting  LABEL_1 : 12\n",
            "#of replies supporting  LABEL_2 : 4\n"
          ]
        }
      ],
      "source": [
        "with open(dir_path + 'explainer_output/544338575240609792.json','r') as f:\n",
        "  dict_to_save2 = json.load(f)\n",
        "\n",
        "gold_label = dict_to_save2['gold_label']\n",
        "predicted_label = most_common(dict_to_save2['predicted_labels'])\n",
        "print('Claim: ', dict_to_save2['source'])\n",
        "\n",
        "print('Gold standard: ',gold_label)\n",
        "print('Predicted_label: ',predicted_label)\n",
        "\n",
        "for label in dict_to_save2['replies'].keys():\n",
        "  print('#of replies supporting ',label,':', len(dict_to_save2['replies'][label]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxbkjJm7yuVC",
        "outputId": "7c5fd258-cffd-4fdb-ff8c-242a704ffa52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input for Summarisation:  #breaking: flag w/ islamic writing held up to window of #sydney cafe. police say up to 50 hostages. #australia pm convenes security team. MENTION MENTION it's the shahadah flag, not the isis flag. MENTION MENTION 10 employees + ?how many customers = ? need verify? MENTION MENTION worth checking this out from MENTION on the flag itself. URL MENTION MENTION that flag is a shahadah flag. bandana on suspect says \"at your service, o muhammad\" URL MENTION MENTION nm - bloody sends electric waves to girls for physical relationships despite having own wife, extrema characterless MENTION MENTION islamic isn't a language MENTION MENTION cnn badly needs to employ reporters who can read. why not say as it is, that it's the islamic flag with shahada on it? MENTION MENTION breaking?? it's been happening for 3 hours now. sheesh. MENTION MENTION gee wonder why no one has a gun. oh that's right. australia bans citizens from having guns. MENTION MENTION #breaking ? its 5 hours into the #sydneysiege how is that breaking? MENTION MENTION where did he get the gun ?no muslim should allowed to carry gun hving gun or buy a gun. MENTION MENTION hang those stupid hostage takers once they have been arrested! stupid dog eating bloody muslims!\n"
          ]
        }
      ],
      "source": [
        "#Preprocess the summarisation input\n",
        "\n",
        "text = [dict_to_save2['source']]\n",
        "text.extend([x['text'] for x in dict_to_save2['replies'][gold_label]])\n",
        "text = ' '.join(text)\n",
        "text = preprocess_tweet(text)\n",
        "print('Input for Summarisation: ', text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyx8Rr38s7eg",
        "outputId": "bfb16a40-6d80-4d57-f09d-64606996104e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A flag with Islamic text written on it is held up to a window of a Sydney cafe, apparently holding hostages hostage. The majority believe that it is the Shahadah flag, not the isis flag.\n"
          ]
        }
      ],
      "source": [
        "print(bart_ft(text,50,25))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77uJmA4488Il"
      },
      "source": [
        "The summary contains a justification for why the claim might be unreliable: the fact that it is a shahada flag and not an isis flag. However, the summary does not address the fact the rumour is no longer 'breaking news', nor that its number of reported hostages might be incorrect."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjWn_jlDEdln"
      },
      "source": [
        "For a different summary, it is also possible to shuffle the replies in the summarisation input according to several criteria: support score to the label, similarity to the claim, time stamp etc. Below is an implementation of sorting wrt to support scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF1wFeBUA1Ge",
        "outputId": "a56c0b3f-6329-44b3-fe65-a4aebfbb02ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(\"@willripleyCNN @CNN Gee wonder why no one has a gun. Oh that's right. Australia bans citizens from having guns.\", 2.4309663223162943), (\"@willripleyCNN @CNN CNN badly needs to employ reporters who can read. Why not say as it is, that it's the Islamic flag with Shahada on it?\", 0.944405505035455), ('@willripleyCNN @CNN That flag is a Shahadah flag. Bandana on suspect says \"At your service, O Muhammad\" http://t.co/4HRFDy4jwE', 0.6537335932273545), (\"@willripleyCNN @CNN Breaking?? It's been happening for 3 hours now. Sheesh.\", 0.2871692694077432), ('@willripleyCNN @CNN NM - bloody sends electric waves to girls for physical relationships despite having own wife, extrema characterless', 0.2250301049290929), ('@willripleyCNN @SteveHuff Worth checking this out from @smh on the flag itself. http://t.co/ORzzRkKuCx', 0.22466616719173943), (\"@willripleyCNN @CNN It's the Shahadah flag, not the ISIS flag.\", 0.22207233265118018), ('@willripleycnn @cnn #Breaking ?  Its 5 hours into the #SydneySiege How is that Breaking?', 0.15187843589718034), (\"@willripleyCNN @CNN Islamic isn't a language\", 0.13821172431846), ('@willripleyCNN @CNN hang those stupid hostage takers once they have been arrested! Stupid dog eating bloody Muslims!', 0.1284188307559893), ('@willripleyCNN @CNN where did he get the gun ?no Muslim should allowed to carry gun hving gun or buy a gun.', 0.12296848283494581), ('@willripleyCNN @CNN 10 employees + ?how many customers  = ? Need verify?', 0.03659833475193127)]\n"
          ]
        }
      ],
      "source": [
        "ordered_replies = []\n",
        "for reply in dict_to_save2['replies'][gold_label]:\n",
        "  for i,x in enumerate(reply['word_attr'][gold_label]):\n",
        "    if ']' in x[0] and i>1 and 'p' in reply['word_attr'][gold_label][i-1] and 'se' in reply['word_attr'][gold_label][i-2]:\n",
        "      start = i\n",
        "      break\n",
        "      \n",
        "  reply_score = sum([word[1] for word in reply['word_attr'][gold_label][start+1:]]) / sum([word[1] for word in reply['word_attr'][gold_label]])\n",
        "  ordered_replies.append((reply['text'],reply_score))\n",
        "\n",
        "ordered_replies.sort(key= lambda x: x[1],reverse=True)\n",
        "print(ordered_replies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcyPyo6ADkui",
        "outputId": "1f51a04d-0f3a-4295-bdca-20a805c6d9dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input for Summarisation:  #breaking: flag w/ islamic writing held up to window of #sydney cafe. police say up to 50 hostages. #australia pm convenes security team. MENTION MENTION gee wonder why no one has a gun. oh that's right. australia bans citizens from having guns. MENTION MENTION cnn badly needs to employ reporters who can read. why not say as it is, that it's the islamic flag with shahada on it? MENTION MENTION that flag is a shahadah flag. bandana on suspect says \"at your service, o muhammad\" URL MENTION MENTION breaking?? it's been happening for 3 hours now. sheesh. MENTION MENTION nm - bloody sends electric waves to girls for physical relationships despite having own wife, extrema characterless MENTION MENTION worth checking this out from MENTION on the flag itself. URL MENTION MENTION it's the shahadah flag, not the isis flag. MENTION MENTION #breaking ? its 5 hours into the #sydneysiege how is that breaking? MENTION MENTION islamic isn't a language MENTION MENTION hang those stupid hostage takers once they have been arrested! stupid dog eating bloody muslims! MENTION MENTION where did he get the gun ?no muslim should allowed to carry gun hving gun or buy a gun. MENTION MENTION 10 employees + ?how many customers = ? need verify?\n"
          ]
        }
      ],
      "source": [
        "text = [dict_to_save2['source']]\n",
        "text.extend([x[0] for x in ordered_replies])\n",
        "text = ' '.join(text)\n",
        "text = preprocess_tweet(text)\n",
        "print('Input for Summarisation: ', text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUOctwlnEBnm",
        "outputId": "84e1986a-b8fc-4d73-a785-edad7132be49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A flag with Islamic text written on it is held up to a window of a Sydney cafe, apparently holding hostages hostage. The majority are shocked and confused about how this could possibly be happening.\n"
          ]
        }
      ],
      "source": [
        "print(bart_ft(text,50,25))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
