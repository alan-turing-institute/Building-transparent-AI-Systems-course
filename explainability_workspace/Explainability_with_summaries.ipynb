{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "df409921c80944eeb65325664be927e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3bb90fa5ab745e682ceb1ccdd55901d",
              "IPY_MODEL_982fa09522974d939b2f063ff14aaa8b",
              "IPY_MODEL_04da007403ef4a1794235e07801aff05"
            ],
            "layout": "IPY_MODEL_694d3ba1c6714639b328ed46085949c6"
          }
        },
        "e3bb90fa5ab745e682ceb1ccdd55901d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4fbfb0844184d87a737558634304c2a",
            "placeholder": "​",
            "style": "IPY_MODEL_fe511bc9c0ae4fc08e30a73796e7f483",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "982fa09522974d939b2f063ff14aaa8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d521b0e87fc34798a57e3d452d507df6",
            "max": 614,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a97be65ce3644a4fa9a6e67fcc285ebe",
            "value": 614
          }
        },
        "04da007403ef4a1794235e07801aff05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f603ebcf41b643b7b9b58f018914dd24",
            "placeholder": "​",
            "style": "IPY_MODEL_35d1b6e42b694e7294ff4cccd95cd613",
            "value": " 614/614 [00:00&lt;00:00, 13.6kB/s]"
          }
        },
        "694d3ba1c6714639b328ed46085949c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4fbfb0844184d87a737558634304c2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe511bc9c0ae4fc08e30a73796e7f483": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d521b0e87fc34798a57e3d452d507df6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a97be65ce3644a4fa9a6e67fcc285ebe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f603ebcf41b643b7b9b58f018914dd24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35d1b6e42b694e7294ff4cccd95cd613": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ae806ce1c3b4dc7b52dcc9a104e96d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ad85f132c5a4be4bfb4ed10d54633c6",
              "IPY_MODEL_7db40c6fa6cb46808b025330940539f0",
              "IPY_MODEL_1b51e270d6b7420a8cdb08ad09ea2f91"
            ],
            "layout": "IPY_MODEL_190dae36eff44495bde920c59ddfdc9b"
          }
        },
        "0ad85f132c5a4be4bfb4ed10d54633c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_967178a1f8ec4f61981cf8bcb903dcd0",
            "placeholder": "​",
            "style": "IPY_MODEL_a062b1486a164fd0a4666d2f8f2a9a9a",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "7db40c6fa6cb46808b025330940539f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d41f888dd084f939a0febca3074a91d",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05b28c87c8a14a05a0310e40d4338493",
            "value": 898823
          }
        },
        "1b51e270d6b7420a8cdb08ad09ea2f91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7b73da740a84bbd963301472a206ad8",
            "placeholder": "​",
            "style": "IPY_MODEL_b90f33f0f87b4241a5279fd63ccca637",
            "value": " 899k/899k [00:00&lt;00:00, 976kB/s]"
          }
        },
        "190dae36eff44495bde920c59ddfdc9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "967178a1f8ec4f61981cf8bcb903dcd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a062b1486a164fd0a4666d2f8f2a9a9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d41f888dd084f939a0febca3074a91d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05b28c87c8a14a05a0310e40d4338493": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7b73da740a84bbd963301472a206ad8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b90f33f0f87b4241a5279fd63ccca637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a1737f0364c428f99602689776c7a35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33e7442fb3c34c6b82fc158543830e5e",
              "IPY_MODEL_7f9bce2c4ad541fd9da125715d2e2e77",
              "IPY_MODEL_ca5d388f3a6c4844a8b5910d9d4f046d"
            ],
            "layout": "IPY_MODEL_637df51db389425c9592d11d8cc9ad67"
          }
        },
        "33e7442fb3c34c6b82fc158543830e5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ef6d4ca6b2e4611bc198f782a3c7a5c",
            "placeholder": "​",
            "style": "IPY_MODEL_52cb5602fe284d03a0ce6be2fb3eb035",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "7f9bce2c4ad541fd9da125715d2e2e77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e0550753e754e938d2431d315e9ccf5",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e60c9bdee9a4421b493ac69b5c8ab24",
            "value": 456318
          }
        },
        "ca5d388f3a6c4844a8b5910d9d4f046d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cca46993b9984a05bc0983dbd2ca3c57",
            "placeholder": "​",
            "style": "IPY_MODEL_b0f9238d6b5b4a8989e50310654818cc",
            "value": " 456k/456k [00:00&lt;00:00, 497kB/s]"
          }
        },
        "637df51db389425c9592d11d8cc9ad67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ef6d4ca6b2e4611bc198f782a3c7a5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52cb5602fe284d03a0ce6be2fb3eb035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e0550753e754e938d2431d315e9ccf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e60c9bdee9a4421b493ac69b5c8ab24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cca46993b9984a05bc0983dbd2ca3c57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0f9238d6b5b4a8989e50310654818cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0dc91831470e47fb93eaf631201dd940": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c3d7bb8dc666481795cf1477cb431ce3",
              "IPY_MODEL_727df4c24a9c417789807d6e8f274fd3",
              "IPY_MODEL_b5f2d875aa12447c852b42056e6a2417"
            ],
            "layout": "IPY_MODEL_95ae9f1dae3345308a2ed261c8e39fe0"
          }
        },
        "c3d7bb8dc666481795cf1477cb431ce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a591fbc5b5d94242aad1f3d5705c6b08",
            "placeholder": "​",
            "style": "IPY_MODEL_2140f1cec8fb46099394aa68dace8d53",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "727df4c24a9c417789807d6e8f274fd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a974ab34e1e04541b316531df68e3c35",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92cd5901f7a14e8ba1adfabe0931582e",
            "value": 1355863
          }
        },
        "b5f2d875aa12447c852b42056e6a2417": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8246a6ed36248768e7984e6fe2a50d9",
            "placeholder": "​",
            "style": "IPY_MODEL_c12492d28dfe45b6aac6e04ed1ed29bc",
            "value": " 1.36M/1.36M [00:01&lt;00:00, 1.23MB/s]"
          }
        },
        "95ae9f1dae3345308a2ed261c8e39fe0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a591fbc5b5d94242aad1f3d5705c6b08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2140f1cec8fb46099394aa68dace8d53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a974ab34e1e04541b316531df68e3c35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92cd5901f7a14e8ba1adfabe0931582e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8246a6ed36248768e7984e6fe2a50d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c12492d28dfe45b6aac6e04ed1ed29bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea7bdeb70e094d3c8c282b6b02ba0913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ac01febe3a247eba139b2062b98126f",
              "IPY_MODEL_455574e6fb334be7adf9c332105f5c68",
              "IPY_MODEL_e85d5b30eb344e10a20fd81fa7897a88"
            ],
            "layout": "IPY_MODEL_eecdffe8d6b54d6897f019d655e624df"
          }
        },
        "9ac01febe3a247eba139b2062b98126f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92e29ff0d6a845738666dbba8e3aac4c",
            "placeholder": "​",
            "style": "IPY_MODEL_33bde1b851c94a24940e0dbe057bd235",
            "value": "Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
          }
        },
        "455574e6fb334be7adf9c332105f5c68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_972088a9720f4bc292d5acfd3160b929",
            "max": 1422008553,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1d05e57cc8543c9820e8e30eb3dcb50",
            "value": 1422008553
          }
        },
        "e85d5b30eb344e10a20fd81fa7897a88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78e9fbcd61f74d858562f8ed8891d619",
            "placeholder": "​",
            "style": "IPY_MODEL_170a7852062747489a1a686f27753f9d",
            "value": " 1.42G/1.42G [01:04&lt;00:00, 21.1MB/s]"
          }
        },
        "eecdffe8d6b54d6897f019d655e624df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92e29ff0d6a845738666dbba8e3aac4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33bde1b851c94a24940e0dbe057bd235": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "972088a9720f4bc292d5acfd3160b929": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1d05e57cc8543c9820e8e30eb3dcb50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78e9fbcd61f74d858562f8ed8891d619": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "170a7852062747489a1a686f27753f9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Summaries as a way to explain Classification models for the Task of Rumour Verification\n",
        "----------"
      ],
      "metadata": {
        "id": "r1CSb4gWOCBz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Table of contents\n"
      ],
      "metadata": {
        "id": "1ej337k9PT63"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">[Summaries as a way to explain Classification models for the Task of Rumour Verification](#scrollTo=r1CSb4gWOCBz)\n",
        "\n",
        ">>[Table of contents](#scrollTo=1ej337k9PT63)\n",
        "\n",
        ">>[Prepare your environment](#scrollTo=QxdiWfqtPd9q)\n",
        "\n",
        ">>[Construct BERT model using the reply thread for rumour verification](#scrollTo=veKfKdZOdn8a)\n",
        "\n",
        ">>[Apply Rationale-based explainer on BERT](#scrollTo=veKfKdZOdn8a)\n",
        "\n",
        ">>[Use scored rationales to create explanation-summary](#scrollTo=BQoAJ_CPdaMI)\n",
        "\n",
        ">>>[Summarise content of Twitter thread which supports the predicted label](#scrollTo=Q0svychHje1o)\n",
        "\n",
        ">>>[Summarise content of Twitter thread which supports the gold standard](#scrollTo=5cXge8Iqm1m6)\n",
        "\n"
      ],
      "metadata": {
        "id": "txR9jNcoQtU9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare your environment"
      ],
      "metadata": {
        "id": "QxdiWfqtPd9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers-interpret==0.6.0\n",
        "!pip install datasets\n",
        "!pip install tweet-preprocessor\n",
        "!pip install emoji==0.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ky1HBDHSQ7Pe",
        "outputId": "f48574ee-a383-46db-aae5-8b4040110463"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers-interpret==0.6.0 in /usr/local/lib/python3.8/dist-packages (0.6.0)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from transformers-interpret==0.6.0) (4.26.1)\n",
            "Requirement already satisfied: captum>=0.3.1 in /usr/local/lib/python3.8/dist-packages (from transformers-interpret==0.6.0) (0.6.0)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.8/dist-packages (from captum>=0.3.1->transformers-interpret==0.6.0) (1.13.1+cu116)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from captum>=0.3.1->transformers-interpret==0.6.0) (3.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from captum>=0.3.1->transformers-interpret==0.6.0) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.0->transformers-interpret==0.6.0) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.0->transformers-interpret==0.6.0) (23.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.0->transformers-interpret==0.6.0) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.0->transformers-interpret==0.6.0) (3.9.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.0->transformers-interpret==0.6.0) (0.12.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.0->transformers-interpret==0.6.0) (0.13.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.0->transformers-interpret==0.6.0) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.0->transformers-interpret==0.6.0) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers>=3.0.0->transformers-interpret==0.6.0) (4.5.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->captum>=0.3.1->transformers-interpret==0.6.0) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->captum>=0.3.1->transformers-interpret==0.6.0) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->captum>=0.3.1->transformers-interpret==0.6.0) (2.8.2)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->captum>=0.3.1->transformers-interpret==0.6.0) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->captum>=0.3.1->transformers-interpret==0.6.0) (4.38.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->captum>=0.3.1->transformers-interpret==0.6.0) (8.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=3.0.0->transformers-interpret==0.6.0) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=3.0.0->transformers-interpret==0.6.0) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=3.0.0->transformers-interpret==0.6.0) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=3.0.0->transformers-interpret==0.6.0) (1.26.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib->captum>=0.3.1->transformers-interpret==0.6.0) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.10.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2023.1.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.12.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (3.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tweet-preprocessor in /usr/local/lib/python3.8/dist-packages (0.6.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: emoji==0.6.0 in /usr/local/lib/python3.8/dist-packages (0.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# connect to gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngLb0Pxie71g",
        "outputId": "3d28ea5f-2a48-47a2-e392-5d937c941f94"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import datasets\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "import preprocessor as p\n",
        "import torch.nn as nn\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from datasets import Dataset, load_metric, load_dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import get_scheduler, AdamW\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from transformers import AutoTokenizer,AutoModelForSequenceClassification, DataCollatorWithPadding,BartForConditionalGeneration\n",
        "from transformers_interpret import MultiLabelClassificationExplainer,SequenceClassificationExplainer\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "6UQvSSxsRF9W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe6250e3-5da4-4fc5-e7b2-53948dc9e4e3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir_path = '/content/gdrive/MyDrive/ResponsibleAI/draft-deliveries/explainability_workspace/'"
      ],
      "metadata": {
        "id": "3GhJOXaN6r9z"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Construct post-level BERT model for rumour verification\n",
        "\n",
        "We train a BERT model using the source tweet (claim of the rumour) and first-level replies (referred as replies for convenience) as input. For the purpose of this study we ignore replies posted deeper in the thread e.g. replies of replies. \n",
        "\n",
        "Training instances are of the form: *source tweet [SEP] reply*. Hence, for a thread with *n* replies, we generate *n* training instances.\n",
        "\n",
        "Note that this enables us to use all the information in the replies and avoid out-of-memory issues which occur in the rationale generation for Section 2. The trade-off is sacrificing some faithfulness as the claim is predicted *n* labels which are aggregated to form a final label.\n",
        "\n",
        "The prediction labels remain the same: \n",
        "\n",
        "*   0 = True\n",
        "*   1 = False\n",
        "* 2 = *Unverified*\n"
      ],
      "metadata": {
        "id": "veKfKdZOdn8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess function for tweets\n",
        "\n",
        "p.set_options(p.OPT.EMOJI, p.OPT.SMILEY)\n",
        "def preprocess_tweet(tweet):\n",
        "    tweet = tweet.lower()\n",
        "    tweet = tweet.replace('\\n','').replace('\\t','')\n",
        "    tweet = re.sub(r'http\\S+', 'URL', tweet)\n",
        "    tweet = re.sub(r'@\\w+', 'MENTION', tweet)\n",
        "    tweet = p.clean(tweet)\n",
        " \n",
        "    return tweet"
      ],
      "metadata": {
        "id": "gYmW9qhezchf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prep_data(fold, cvfolds):  \n",
        "    # We only use the original (unshuffled) data for testing\n",
        "    test = {}\n",
        "    test['data'] = []\n",
        "    test['data'] = cvfolds[fold]\n",
        "    \n",
        "    savepath1 = dir_path + \"test_\" + fold + \".json\"\n",
        "    with open(savepath1, 'w+') as f:\n",
        "        json.dump(test, f)    \n",
        "    testset = load_dataset('json', data_files=savepath1, field='data')\n",
        "    \n",
        "    train = {}\n",
        "    train['data'] = []\n",
        "    for fo in list(cvfolds.keys()): \n",
        "        if fo!=fold:\n",
        "            train['data'].extend(cvfolds[fo])\n",
        "    savepath2 = dir_path + \"train_\" + fold + \".json\"\n",
        "    with open(savepath2, 'w+') as f:\n",
        "        json.dump(train, f)\n",
        "    trainset = load_dataset('json', data_files=savepath2, field='data')\n",
        "    \n",
        "    return testset, trainset    "
      ],
      "metadata": {
        "id": "VLnt58OwegJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"vinai/bertweet-large\" # \"bert-base-uncased\" # \"cardiffnlp/twitter-roberta-base\" #\"roberta-large\" #\"bert-base-uncased\" #\"digitalepidemiologylab/covid-twitter-bert-v2\" #\"cardiffnlp/twitter-roberta-base\" # \"roberta-large\" # \"bert-base-uncased\" # # #  # # # # #\" # # #\"digitalepidemiologylab/covid-twitter-bert-v2\" #\"roberta-large\"#\"bert-base-uncased\" #\"bert-large-cased\" #\"roberta-large\" #\"bert-base-uncased\" #\"bert-large-cased\" # #\"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "bs = 4\n",
        "\n",
        "def tokenize_function(example):   \n",
        "    return tokenizer(example['pp_source_reply'], truncation=True,max_length=512)"
      ],
      "metadata": {
        "id": "inSqkFcP3EPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reset_weights(m):\n",
        "  '''\n",
        "    Try resetting model weights to avoid\n",
        "    weight leakage.\n",
        "  '''\n",
        "  for layer in m.children():\n",
        "   if hasattr(layer, 'reset_parameters'):\n",
        "    print(f'Reset trainable parameters of layer = {layer}')\n",
        "    layer.reset_parameters()"
      ],
      "metadata": {
        "id": "Q4MPSxUU3S6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the model is trained on a leave-one-event out cross validation setting."
      ],
      "metadata": {
        "id": "oNUtxxyY4j2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load data & train the model\n",
        "\n",
        "with open(os.path.join(dir_path, 'pheme_reply_entries.json'),'r') as f:\n",
        "    cvfolds = json.load(f)\n",
        "\n",
        "for fold in list(cvfolds.keys()):\n",
        " \n",
        "    testset, trainset = prep_data(fold, cvfolds)\n",
        "    testset_ids = list(testset['train']['idx'])\n",
        "    \n",
        "    print (len(testset_ids))\n",
        "  \n",
        "    tokenized_datasets = trainset.map(tokenize_function, batched=True)\n",
        "    tokenized_datasets = tokenized_datasets.remove_columns([\"sentence1\", \"idx\",\"source_reply\",\"pp_source_reply\"])\n",
        "    tokenized_datasets.set_format(\"torch\")\n",
        "    print(tokenized_datasets)\n",
        "    \n",
        "    tokenized_testset = testset.map(tokenize_function, batched=True)\n",
        "    tokenized_testset = tokenized_testset.remove_columns([\"sentence1\", \"idx\",\"source_reply\",\"pp_source_reply\"])\n",
        "    tokenized_testset.set_format(\"torch\",columns=['input_ids', 'attention_mask', 'labels']) #'token_type_ids', for bert?\n",
        "    \n",
        "    train_dataloader = DataLoader(\n",
        "        tokenized_datasets[\"train\"], shuffle=True, batch_size=bs, collate_fn=data_collator)\n",
        "   \n",
        "    eval_dataloader = DataLoader(\n",
        "        tokenized_testset[\"train\"], batch_size=bs, collate_fn=data_collator)\n",
        "    \n",
        "    model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3)\n",
        "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "    model.to(device)\n",
        "    \n",
        "    optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "    \n",
        "    num_epochs = 10\n",
        "    num_training_steps = num_epochs * len(train_dataloader)\n",
        "    lr_scheduler = get_scheduler(\"linear\",optimizer=optimizer,num_warmup_steps=0,num_training_steps=num_training_steps)\n",
        "    #print(num_training_steps)\n",
        "\n",
        "    progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        for batch in train_dataloader:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(**batch)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            lr_scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "            progress_bar.update(1)\n",
        "            \n",
        "    # Save state dictionary    \n",
        "    model_path = dir_path'+'model_{}'.format(fold)\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    \n",
        "\n",
        "    all_test_predictions = []\n",
        "    all_test_labels = []\n",
        "    metric = load_metric(\"accuracy\", \"f1\")\n",
        "    model.eval()\n",
        "    for batch in eval_dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch)\n",
        "\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "        all_test_predictions.extend(predictions)\n",
        "        all_test_labels.extend(batch['labels'])\n",
        "        metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "    metric.compute()\n",
        "    print(fold,all_test_predictions)\n",
        "    all_test_predictions = [int(i) for i in all_test_predictions]\n",
        "    all_test_labels = [int(i) for i in all_test_labels]\n",
        "    \n",
        "    print(accuracy_score (all_test_labels, all_test_predictions))\n",
        "    print(f1_score(all_test_labels, all_test_predictions, average='macro'))\n",
        "    \n",
        "    model.apply(reset_weights) "
      ],
      "metadata": {
        "id": "qOQzIuVk3ZcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Apply Rationale-based explainer on BERT"
      ],
      "metadata": {
        "id": "7JQ_jmYS1OlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the Rumour Verification Model trained for 'sydneysiege\" using the state dictionary. This is found [here](https://drive.google.com/file/d/1sPbMMXBE_RjWRBveIs0tOXG1km6SnDAs/view?usp=sharing).\n",
        "\n"
      ],
      "metadata": {
        "id": "uWMGWv3X3DTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  checkpoint = \"vinai/bertweet-large\" # \"bert-base-uncased\" # \"cardiffnlp/twitter-roberta-base\" #\"roberta-large\" #\"bert-base-uncased\" #\"digitalepidemiologylab/covid-twitter-bert-v2\" #\"cardiffnlp/twitter-roberta-base\" # \"roberta-large\" # \"bert-base-uncased\" # # #  # # # # #\" # # #\"digitalepidemiologylab/covid-twitter-bert-v2\" #\"roberta-large\"#\"bert-base-uncased\" #\"bert-large-cased\" #\"roberta-large\" #\"bert-base-uncased\" #\"bert-large-cased\" # #\"bert-base-uncased\"\n",
        "  tokenizer = AutoTokenizer.from_pretrained(checkpoint,truncation=True,max_length=512)   \n",
        "\n",
        "  #Load the trained BERT model\n",
        "  saved_model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3)\n",
        "  device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "  saved_model.load_state_dict(torch.load(dir_path + \"model_sydneysiege\",map_location=torch.device('cpu')))\n",
        "  #saved_model.to(\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304,
          "referenced_widgets": [
            "df409921c80944eeb65325664be927e7",
            "e3bb90fa5ab745e682ceb1ccdd55901d",
            "982fa09522974d939b2f063ff14aaa8b",
            "04da007403ef4a1794235e07801aff05",
            "694d3ba1c6714639b328ed46085949c6",
            "e4fbfb0844184d87a737558634304c2a",
            "fe511bc9c0ae4fc08e30a73796e7f483",
            "d521b0e87fc34798a57e3d452d507df6",
            "a97be65ce3644a4fa9a6e67fcc285ebe",
            "f603ebcf41b643b7b9b58f018914dd24",
            "35d1b6e42b694e7294ff4cccd95cd613",
            "7ae806ce1c3b4dc7b52dcc9a104e96d9",
            "0ad85f132c5a4be4bfb4ed10d54633c6",
            "7db40c6fa6cb46808b025330940539f0",
            "1b51e270d6b7420a8cdb08ad09ea2f91",
            "190dae36eff44495bde920c59ddfdc9b",
            "967178a1f8ec4f61981cf8bcb903dcd0",
            "a062b1486a164fd0a4666d2f8f2a9a9a",
            "3d41f888dd084f939a0febca3074a91d",
            "05b28c87c8a14a05a0310e40d4338493",
            "a7b73da740a84bbd963301472a206ad8",
            "b90f33f0f87b4241a5279fd63ccca637",
            "9a1737f0364c428f99602689776c7a35",
            "33e7442fb3c34c6b82fc158543830e5e",
            "7f9bce2c4ad541fd9da125715d2e2e77",
            "ca5d388f3a6c4844a8b5910d9d4f046d",
            "637df51db389425c9592d11d8cc9ad67",
            "0ef6d4ca6b2e4611bc198f782a3c7a5c",
            "52cb5602fe284d03a0ce6be2fb3eb035",
            "6e0550753e754e938d2431d315e9ccf5",
            "1e60c9bdee9a4421b493ac69b5c8ab24",
            "cca46993b9984a05bc0983dbd2ca3c57",
            "b0f9238d6b5b4a8989e50310654818cc",
            "0dc91831470e47fb93eaf631201dd940",
            "c3d7bb8dc666481795cf1477cb431ce3",
            "727df4c24a9c417789807d6e8f274fd3",
            "b5f2d875aa12447c852b42056e6a2417",
            "95ae9f1dae3345308a2ed261c8e39fe0",
            "a591fbc5b5d94242aad1f3d5705c6b08",
            "2140f1cec8fb46099394aa68dace8d53",
            "a974ab34e1e04541b316531df68e3c35",
            "92cd5901f7a14e8ba1adfabe0931582e",
            "e8246a6ed36248768e7984e6fe2a50d9",
            "c12492d28dfe45b6aac6e04ed1ed29bc",
            "ea7bdeb70e094d3c8c282b6b02ba0913",
            "9ac01febe3a247eba139b2062b98126f",
            "455574e6fb334be7adf9c332105f5c68",
            "e85d5b30eb344e10a20fd81fa7897a88",
            "eecdffe8d6b54d6897f019d655e624df",
            "92e29ff0d6a845738666dbba8e3aac4c",
            "33bde1b851c94a24940e0dbe057bd235",
            "972088a9720f4bc292d5acfd3160b929",
            "e1d05e57cc8543c9820e8e30eb3dcb50",
            "78e9fbcd61f74d858562f8ed8891d619",
            "170a7852062747489a1a686f27753f9d"
          ]
        },
        "id": "DiL4P9KM3Dzx",
        "outputId": "fae9b5dd-71d2-418f-988a-6014ac9724f7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df409921c80944eeb65325664be927e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ae806ce1c3b4dc7b52dcc9a104e96d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a1737f0364c428f99602689776c7a35"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0dc91831470e47fb93eaf631201dd940"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea7bdeb70e094d3c8c282b6b02ba0913"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at vinai/bertweet-large were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use a toy test set which contains 13 threads from the sydney-siege fold. \n",
        "Let's run the explainer model on a a particular example: take the first reply in the first twitter thread of the test sample. Run BERT on the concatenation between the source tweet and the reply."
      ],
      "metadata": {
        "id": "cX0_j4sVD1t9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " with open(dir_path +\"explainer_input_test.json\",'r') as f:\n",
        "    test = json.load(f)\n",
        "\n",
        "print(len(test['sydneysiege']))\n",
        "\n",
        "print('Trial run for the explainer')\n",
        "\n",
        "instance = test['sydneysiege'][0]\n",
        "print(instance)\n",
        "print('Claim: ', instance['sentence1'])\n",
        "print('Reply: ', instance['replies1'][0])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgJdBVDDbKQA",
        "outputId": "ade960c5-3510-4b28-dd22-c638f1db1e0e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n",
            "Trial run for the explainer\n",
            "{'replies1': ['@newscomauHQ I hope this is true', '@newscomauHQ lets hope they are ok.', '@newscomauHQ hope they are safe', 'BREAKING: Hostages are running out of the cafe #sydneysiege v @newscomauHQ', 'OMG is this true “@newscomauHQ: BREAKING: Hostages are running out of the cafe #sydneysiege”', '@newscomauHQ If this is true, what great news.  Is incident over?', '“@newscomauHQ: BREAKING: Hostages are running out of the cafe #sydneysiege” please let this be true', '“@newscomauHQ: BREAKING: Hostages are running out of the cafe #sydneysiege” I hope this is true', '@newscomauHQ Please let this be true!', '@newscomauHQ @mirandadevine if this is true, I fear this could turn very nasty very quickly as the remaining ones may be abused by terrorist', '@newscomauHQ how bout keeping that quiet @neontaster'], 'idx': 544350480780914688, 'labels': 0, 'sentence1': 'BREAKING: Hostages are running out of the cafe #sydneysiege'}\n",
            "Claim:  BREAKING: Hostages are running out of the cafe #sydneysiege\n",
            "Reply:  @newscomauHQ I hope this is true\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the transformers-interpret library which relies on Integrated Gradients as laid out in the paper Axiomatic Attributions for Deep Networks (Sundararajan et al.,2017 https://arxiv.org/pdf/1703.01365.pdf). This method will ouput an attribution score for each token in the tokenized text (local explanation). \n",
        "\n",
        "The main ideas behind this algorithm follow:\n",
        "\n",
        "\n",
        "1.   Define instance x and calculate prediction f(x)\n",
        "2.   Define baseline point x_0 which is usually represented by the empty string.\n",
        "3.   Construct n intermediary points between x and x_0 via linear interpolation. \n",
        "4.   Calculate the gradients at each of the n steps.\n",
        "5.   Approximate integral between baseline and input by accumulating these gradients -> usually by taking the mean average of all gradients.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "See more attribution score-based explanation types in Lecture 2.1."
      ],
      "metadata": {
        "id": "nToHO_44HxnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Find which replies contributed for the prediction\n",
        "cls_explainer = MultiLabelClassificationExplainer(saved_model, tokenizer)\n",
        "mini_text_input = instance['sentence1'] + ' [SEP] ' + instance['replies1'][0]\n",
        "mini_text_input = preprocess_tweet(mini_text_input)\n",
        "word_attributions = cls_explainer(mini_text_input,internal_batch_size=2)\n",
        "\n"
      ],
      "metadata": {
        "id": "vAhvjYXZSowX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_attributions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxDGD2xde6QU",
        "outputId": "e1034de1-0eab-48ba-9de3-0b85d95fe128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'LABEL_0': [('<s>', 0.0), ('breaking', 0.02013541385752795), (':', -0.008238418946795948), ('hostages', 0.059403423359093446), ('are', 0.030279127155955345), ('running', -0.368238855365563), ('out', -0.10688875418590367), ('of', 0.15389767020172143), ('the', 0.23447527356990894), ('cafe', 0.21108824998935136), ('#', 0.12382871183519698), ('sy', 0.6533669436296611), ('d', -0.18311717640404573), ('neys', 0.16205672042505898), ('iege', 0.10915219608127644), ('[', -0.21827548559888135), ('se', 0.09449431965693357), ('p', 0.01769258883053469), (']', 0.08033574402856011), ('M', 0.3725545238239933), ('ENTION', 0.045396408027896365), ('i', -0.030684950591865295), ('hope', -0.0019691545662734815), ('this', -0.003057696333650379), ('is', -0.04093257733950469), ('true', -0.06384394519442635), ('</s>', 0.0)], 'LABEL_1': [('<s>', 0.0), ('breaking', 0.12755099058708746), (':', -0.0006147288380746749), ('hostages', -0.028348606078918894), ('are', -0.11490996673405893), ('running', -0.10193128329710545), ('out', -0.09190818554181523), ('of', 0.01438803370527067), ('the', 0.20045245946051213), ('cafe', 0.050452635901356825), ('#', -0.28686935484690157), ('sy', -0.8884578405479613), ('d', -0.053974799468788484), ('neys', 0.01139593308791298), ('iege', 0.001987871696091771), ('[', 0.04460637159801951), ('se', 0.077816087952436), ('p', 0.08074165215605222), (']', 0.023222659720112025), ('M', 0.12063844285634867), ('ENTION', -0.002907420889158949), ('i', -0.011190157142790685), ('hope', 0.01421195721622172), ('this', 0.041704026772230805), ('is', 0.019354203068697614), ('true', 0.03386022330221182), ('</s>', 0.0)], 'LABEL_2': [('<s>', 0.0), ('breaking', -0.05478534452628623), (':', 0.009145432438145976), ('hostages', -0.05750862818439478), ('are', -0.0034641955702878137), ('running', 0.42793781792569663), ('out', 0.14025311895883302), ('of', -0.1715884134908654), ('the', -0.30736563814523143), ('cafe', -0.2432567601200999), ('#', -0.06127046357879238), ('sy', -0.4841487838136809), ('d', 0.21364978871336268), ('neys', -0.1797191018304455), ('iege', -0.11958512301920221), ('[', 0.22663789514255617), ('se', -0.1231059159172778), ('p', -0.04007613264584877), (']', -0.09361318405184055), ('M', -0.437458798562404), ('ENTION', -0.048774541033241414), ('i', 0.03635339074282419), ('hope', -0.001508648290629542), ('this', -0.0073950594194065146), ('is', 0.03967319645358035), ('true', 0.060934545172740336), ('</s>', 0.0)]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cls_explainer.visualize(\"multilabel_viz.html\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "4C6qqC4PS62Z",
        "outputId": "bbfe5e65-a375-435c-8c65-a8d0a80e4bba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>n/a</b></text></td><td><text style=\"padding-right:2em\"><b> (0.62)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_0</b></text></td><td><text style=\"padding-right:2em\"><b>1.34</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #s                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> breaking                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> :                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hostages                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> are                    </font></mark><mark style=\"background-color: hsl(0, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> running                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> out                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> cafe                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #                    </font></mark><mark style=\"background-color: hsl(120, 75%, 68%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> sy                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> d                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> neys                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> iege                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> se                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> p                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> M                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ENTION                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> i                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hope                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> this                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> true                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>n/a</b></text></td><td><text style=\"padding-right:2em\"><b> (0.00)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1</b></text></td><td><text style=\"padding-right:2em\"><b>-0.72</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #s                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> breaking                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> :                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hostages                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> are                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> running                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> out                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> cafe                    </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #                    </font></mark><mark style=\"background-color: hsl(0, 75%, 65%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> sy                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> d                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> neys                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> iege                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> se                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> p                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> M                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ENTION                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> i                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hope                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> this                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> true                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>n/a</b></text></td><td><text style=\"padding-right:2em\"><b> (0.38)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_2</b></text></td><td><text style=\"padding-right:2em\"><b>-1.28</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #s                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> breaking                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> :                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hostages                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> are                    </font></mark><mark style=\"background-color: hsl(120, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> running                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> out                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> cafe                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #                    </font></mark><mark style=\"background-color: hsl(0, 75%, 81%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> sy                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> d                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> neys                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> iege                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> se                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> p                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> M                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ENTION                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> i                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hope                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> this                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> true                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark></td><tr></table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>n/a</th><th>Prediction Score</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>n/a</b></text></td><td><text style=\"padding-right:2em\"><b> (0.62)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_0</b></text></td><td><text style=\"padding-right:2em\"><b>1.34</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #s                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> breaking                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> :                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hostages                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> are                    </font></mark><mark style=\"background-color: hsl(0, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> running                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> out                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> cafe                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #                    </font></mark><mark style=\"background-color: hsl(120, 75%, 68%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> sy                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> d                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> neys                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> iege                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> se                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> p                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> M                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ENTION                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> i                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hope                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> this                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> true                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>n/a</b></text></td><td><text style=\"padding-right:2em\"><b> (0.00)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1</b></text></td><td><text style=\"padding-right:2em\"><b>-0.72</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #s                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> breaking                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> :                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hostages                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> are                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> running                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> out                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> cafe                    </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #                    </font></mark><mark style=\"background-color: hsl(0, 75%, 65%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> sy                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> d                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> neys                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> iege                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> se                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> p                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> M                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ENTION                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> i                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hope                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> this                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> true                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>n/a</b></text></td><td><text style=\"padding-right:2em\"><b> (0.38)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_2</b></text></td><td><text style=\"padding-right:2em\"><b>-1.28</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #s                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> breaking                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> :                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hostages                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> are                    </font></mark><mark style=\"background-color: hsl(120, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> running                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> out                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> cafe                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #                    </font></mark><mark style=\"background-color: hsl(0, 75%, 81%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> sy                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> d                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> neys                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> iege                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> se                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> p                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> M                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ENTION                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> i                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hope                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> this                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> true                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark></td><tr></table>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As seen in the visualisation above, the input's final attribution score is the sum of all individual attribution tokens. This is the highest for LABEL_0 which is also the predicted label for this instance."
      ],
      "metadata": {
        "id": "GnzN-19zN7lO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gold_label = 'LABEL_' + str(instance['labels'])\n",
        "predicted_label = cls_explainer.predicted_class_name\n",
        "print(\"Predicted label \",predicted_label)\n",
        "print(\"Gold Standard: \", gold_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuHWuYVomUi0",
        "outputId": "0df1848b-542d-4c7d-d653-35978f5f8a43"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label  LABEL_0\n",
            "Gold Standard:  LABEL_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, we notice that different rationales (subsets of the input) may align with other labels and thus contribute negatively to the prediction. \n",
        "In our case, we are interested to check which label has the highest summed attribution score with respect to the tokens in each reply. We use the separator [SEP] to indentify the span of the reply text from the claim text.\n",
        "\n",
        "For this example, we find that the reply \"I hope this is true\" will contribute positively to the overall prediction."
      ],
      "metadata": {
        "id": "y2s2R4d6NtYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Indentify which label the reply contributes to the most.\n",
        "\n",
        "max_score = -1000\n",
        "supporting_label = ''\n",
        "start = 0\n",
        "for label in word_attributions.keys():\n",
        "    #Find position of separator token\n",
        "    for i,x in enumerate(word_attributions[label]):\n",
        "      if ']' in x[0] and i>1 and 'p' in word_attributions[label][i-1] and 'se' in word_attributions[label][i-2]:\n",
        "        start = i\n",
        "        break\n",
        "    #Check contribution score of the reply's specific location\n",
        "    reply_contribution = sum([word[1] for word in word_attributions[label][start+1:]])\n",
        "    if reply_contribution>max_score:\n",
        "        max_score = reply_contribution\n",
        "        supporting_label = label\n",
        "\n",
        "print('Label most aligned with the reply: ', supporting_label)"
      ],
      "metadata": {
        "id": "94fjLbIjlUUW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f41c22d2-fd58-4515-b78c-2792f44b6bd5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label most aligned with the reply:  LABEL_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now apply this step to all replies in the thread. This process creates a partition of the replies with respect to the label they contribute to the most. "
      ],
      "metadata": {
        "id": "pwn4ZnICgQJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Now apply this step to all replies in the thread. We will find a partition of the replies wrt to each aligned label\n",
        "\n",
        "cls_explainer = MultiLabelClassificationExplainer(saved_model, tokenizer)\n",
        "contributions_label = {'LABEL_0':[],'LABEL_1':[],'LABEL_2':[]}\n",
        "predicted_labels = []\n",
        "\n",
        "for reply in instance['replies1']:\n",
        "\n",
        "  mini_text_input = instance['sentence1'] + ' [SEP] ' + reply\n",
        "  mini_text_input = preprocess_tweet(mini_text_input)\n",
        "  cls_explainer = MultiLabelClassificationExplainer(saved_model, tokenizer)\n",
        "  word_attributions = cls_explainer(mini_text_input,internal_batch_size=2)\n",
        "  \n",
        "  # For each source+reply, the model will predict a label. This might not be a very good indicator of reply alignment since the source tweet dictates the annotation\n",
        "  predicted_label = cls_explainer.predicted_class_name\n",
        "  predicted_labels.append(predicted_label)\n",
        "  print(predicted_label)\n",
        "    \n",
        "  #___We want to find the label that this reply contributes to the most___\n",
        "  max_score = -1000\n",
        "  supporting_label = ''\n",
        "\n",
        "  for label in contributions_label.keys():\n",
        "      #Find position of separator token\n",
        "      for i,x in enumerate(word_attributions[label]):\n",
        "        if ']' in x[0] and i>1 and 'p' in word_attributions[label][i-1] and 'se' in word_attributions[label][i-2]:\n",
        "          start = i\n",
        "          break\n",
        "      #Check contribution score of the reply's specific location\n",
        "      reply_contribution = sum([word[1] for word in word_attributions[label][start+1:]])\n",
        "      if reply_contribution>max_score:\n",
        "          max_score = reply_contribution\n",
        "          supporting_label = label\n",
        "          \n",
        "  contributions_label[supporting_label].append({'text':reply,'word_attr':word_attributions})\n",
        "\n",
        "dict_to_save = {'replies':contributions_label, 'predicted_labels':predicted_labels,'source':instance['sentence1'],'gold_label':gold_label}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--PUSkCm3wON",
        "outputId": "41393102-c72c-423c-b33e-7b014af79b94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LABEL_0\n",
            "LABEL_0\n",
            "LABEL_0\n",
            "LABEL_0\n",
            "LABEL_0\n",
            "LABEL_0\n",
            "LABEL_0\n",
            "LABEL_0\n",
            "LABEL_0\n",
            "LABEL_0\n",
            "LABEL_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As calculating integrated gradients occurs over several steps (default 50) and all replies within the thread, the construction of the word attribution dictionaries can be quite long depending on the computing resources used. \n",
        "Files containing the explainer outputs are are provided in .json format in the folder *explainer_output* for each thread in the toy test set. These dictionaries are organised as:\n",
        "\n",
        "\n",
        "\n",
        "*   'replies': contains a dictionary of reply contributions for each label\n",
        "  \n",
        "*   'predicted labels': contains the predicted labels for each (source, reply) pair in the thread. Note that most predicted labels are consistent across all replies.\n",
        "*   'source': text of source (equivalent to rumour claim)\n",
        "*   'gold_label': the veracity of the source claim\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7WlkOfmV9NbA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Use scored rationales to create explanation-summary"
      ],
      "metadata": {
        "id": "BQoAJ_CPdaMI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The trained summarisation model is found [here](https://drive.google.com/drive/folders/1cUrIDM4C6vVM1Rha0UJ9Pg6Ds33cUg33?usp=sharing). Download it and put it in your workspace folder. This is the same model we trained in the *Microblog Opinion Summarisation* notebook."
      ],
      "metadata": {
        "id": "VVO2QAWDindc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load summarisation model\n",
        "\n",
        "model_name_ft = dir_path + 'BART_model'\n",
        "model_ft = BartForConditionalGeneration.from_pretrained(model_name_ft)\n",
        "tokenizer_ft = AutoTokenizer.from_pretrained(model_name_ft)\n",
        "\n",
        "\n",
        "def bart_ft(text,max_length,min_length):\n",
        "    inputs = tokenizer_ft.encode(text, return_tensors=\"pt\", max_length=1024)\n",
        "    outputs = model_ft.generate(inputs, max_length=max_length, min_length=min_length, length_penalty=2.0, num_beams=4, early_stopping=True,no_repeat_ngram_size=4)\n",
        "\n",
        "    summary = tokenizer_ft.decode(outputs[0],skip_special_tokens=True)\n",
        "    return summary\n",
        "\n"
      ],
      "metadata": {
        "id": "RXEo3CGjsx1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summarise content of Twitter thread which aligns with the predicted label.\n",
        "\n",
        "From the previous step, we have indentified the replies aligning with the prediction. Use the concatenation of the claim text (for context) and these replies as the input for the summarisation step."
      ],
      "metadata": {
        "id": "Q0svychHje1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Heuristic to use for determining the aggregated predicted label of the Twitter thread: We choose the most frequent label. \n",
        "from collections import Counter\n",
        "\n",
        "def most_common(mylist):\n",
        "    data = Counter(mylist)\n",
        "    return data.most_common(1)[0][0]"
      ],
      "metadata": {
        "id": "flwFvXFWpqZp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell if you want to obtain the explanation dictionary dict_to_save from the previous section. \n",
        "with open(dir_path + 'explainer_output/544350480780914688.json','r') as f:\n",
        "  dict_to_save = json.load(f)"
      ],
      "metadata": {
        "id": "5oQ01kexv0Zi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show the positive rationales in the replies that align with the prediction."
      ],
      "metadata": {
        "id": "TgticSd4jT4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_label = most_common(dict_to_save[\"predicted_labels\"])\n",
        "\n",
        "for tweet in dict_to_save['replies'][predicted_label]:\n",
        "  scored_tokens = tweet[\"word_attr\"][predicted_label]\n",
        "  #Find position of separator token\n",
        "  for i,x in enumerate(scored_tokens):\n",
        "    if ']' in x[0] and i>1 and 'p' in scored_tokens[i-1] and 'se' in scored_tokens[i-2]:\n",
        "      start = i\n",
        "      break\n",
        "  positive_rationales = []\n",
        "  for i,x in enumerate(scored_tokens):\n",
        "    if i<start + 1:\n",
        "      continue\n",
        "    else:\n",
        "      if x[1]>0 and x[0].isalpha():\n",
        "        positive_rationales.append(x[0])\n",
        "  print(preprocess_tweet(tweet['text']))\n",
        "  print('Rationales aligning with the prediction: ',positive_rationales)\n",
        "  print()      \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TfyHqNUotu_",
        "outputId": "8c172e0a-d5a9-430a-d365-b8432071ee29"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MENTION i hope this is true\n",
            "Rationales aligning with the prediction:  ['M', 'ENTION']\n",
            "\n",
            "MENTION lets hope they are ok.\n",
            "Rationales aligning with the prediction:  ['M', 'ENTION', 'lets', 'hope', 'they', 'are']\n",
            "\n",
            "MENTION hope they are safe\n",
            "Rationales aligning with the prediction:  ['M', 'ENTION', 'they', 'are']\n",
            "\n",
            "breaking: hostages are running out of the cafe #sydneysiege v MENTION\n",
            "Rationales aligning with the prediction:  ['breaking', 'are', 'out', 'cafe', 'neys', 'iege']\n",
            "\n",
            "MENTION if this is true, what great news. is incident over?\n",
            "Rationales aligning with the prediction:  ['this', 'is', 'true', 'great', 'news', 'incident', 'over']\n",
            "\n",
            "MENTION: breaking: hostages are running out of the cafe #sydneysiege i hope this is true\n",
            "Rationales aligning with the prediction:  ['breaking', 'are', 'out', 'of', 'cafe', 'neys', 'iege', 'i', 'hope', 'this']\n",
            "\n",
            "MENTION please let this be true!\n",
            "Rationales aligning with the prediction:  ['M', 'ENTION', 'please', 'let', 'this', 'be', 'true']\n",
            "\n",
            "MENTION how bout keeping that quiet MENTION\n",
            "Rationales aligning with the prediction:  ['M', 'ENTION', 'bout', 'keeping', 'that']\n",
            "\n",
            "omg is this true MENTION: breaking: hostages are running out of the cafe #sydneysiege\n",
            "Rationales aligning with the prediction:  ['o', 'mg', 'out', 'of', 'the', 'cafe', 'neys', 'iege']\n",
            "\n",
            "MENTION: breaking: hostages are running out of the cafe #sydneysiege please let this be true\n",
            "Rationales aligning with the prediction:  ['M', 'breaking', 'are', 'out', 'of', 'cafe', 'neys', 'iege', 'please', 'this', 'be']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the summarisation input from the replies which show most alignment to the predicted label. We use the full text of the replies identified in the previous concatenated with the claim text for the summariser.\n"
      ],
      "metadata": {
        "id": "kD_VxRUipiZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess the summarisation input\n",
        "\n",
        "text = [dict_to_save['source']]\n",
        "text.extend([x['text'] for x in dict_to_save['replies'][predicted_label]])\n",
        "text = ' '.join(text)\n",
        "text = preprocess_tweet(text)\n",
        "print('Input for Summarisation: ', text)"
      ],
      "metadata": {
        "id": "-ZENlz-9xKUP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "512733ca-76bb-40da-8556-0674301c8a0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input for Summarisation:  breaking: hostages are running out of the cafe #sydneysiege MENTION i hope this is true MENTION lets hope they are ok. MENTION hope they are safe breaking: hostages are running out of the cafe #sydneysiege v MENTION omg is this true MENTION: breaking: hostages are running out of the cafe #sydneysiege MENTION if this is true, what great news. is incident over? MENTION: breaking: hostages are running out of the cafe #sydneysiege please let this be true MENTION: breaking: hostages are running out of the cafe #sydneysiege i hope this is true MENTION please let this be true! MENTION how bout keeping that quiet MENTION\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(bart_ft(text,50,25))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPU1wYf3lwPM",
        "outputId": "69ba66ff-24ae-412f-e004-8e360a4ecc02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " hostages are reportedly running out of the Sydney siege cafe The majority are hoping that this is true and are concerned for the safety of the hostages inside.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The summary successfully explains why the claim is predicted to be true as the majority of users express hope for the good news regarding the escape of some hostages."
      ],
      "metadata": {
        "id": "nNKU2kJL7_O5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summarise content of Twitter thread which aligns with the gold standard.\n",
        "\n",
        "In the cases where the model makes an incorrect prediction, we can choose to provide a justification for the correct answer. \n",
        "\n",
        "We select an example of a thread (found in *explainer_output/544338575240609792.json*) where a false rumour is predicted as true. Despite the incorrect final judgement of the RV step, the explainer model correctly uncovers the replies which align with the gold standard. \n",
        "\n",
        "This is in line with published work (Ma et al, ACL 2017; Li et al, EMNLP 2019; Bian et al,AAAI 2020) that found user interactions valuable for determining the veracity of rumours on social media."
      ],
      "metadata": {
        "id": "5cXge8Iqm1m6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(dir_path + 'explainer_output/544338575240609792.json','r') as f:\n",
        "  dict_to_save2 = json.load(f)\n",
        "\n",
        "gold_label = dict_to_save2['gold_label']\n",
        "predicted_label = most_common(dict_to_save2['predicted_labels'])\n",
        "print('Claim: ', dict_to_save2['source'])\n",
        "\n",
        "print('Gold standard: ',gold_label)\n",
        "print('Predicted_label: ',predicted_label)\n",
        "\n",
        "for label in dict_to_save2['replies'].keys():\n",
        "  print('#of replies supporting ',label,':', len(dict_to_save2['replies'][label]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rN6bgDZnRbc",
        "outputId": "301b731f-1f75-4825-93a9-c13fa2d536b8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Claim:  #BREAKING: Flag w/ Islamic writing held up to window of #Sydney cafe. Police say up to 50 hostages. #Australia PM convenes security team.\n",
            "Gold standard:  LABEL_1\n",
            "Predicted_label:  LABEL_0\n",
            "#of replies supporting  LABEL_0 : 1\n",
            "#of replies supporting  LABEL_1 : 12\n",
            "#of replies supporting  LABEL_2 : 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show the positive rationales in the replies that align with the gold standard."
      ],
      "metadata": {
        "id": "bLIcQIyNw1-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for tweet in dict_to_save2['replies'][gold_label]:\n",
        "  scored_tokens = tweet[\"word_attr\"][gold_label]\n",
        "  #Find position of separator token\n",
        "  for i,x in enumerate(scored_tokens):\n",
        "    if ']' in x[0] and i>1 and 'p' in scored_tokens[i-1] and 'se' in scored_tokens[i-2]:\n",
        "      start = i\n",
        "      break\n",
        "  positive_rationales = []\n",
        "  for i,x in enumerate(scored_tokens):\n",
        "    if i<start + 1:\n",
        "      continue\n",
        "    else:\n",
        "      if x[1]>0 and x[0].isalpha():\n",
        "        positive_rationales.append(x[0])\n",
        "  print(preprocess_tweet(tweet['text']))\n",
        "  print('Rationales aligning with the gold standard: ',positive_rationales)\n",
        "  print()     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPgAqWIrwdt5",
        "outputId": "8b00a9a9-a8e8-4448-e159-3fbec7b771b3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MENTION MENTION it's the shahadah flag, not the isis flag.\n",
            "Rationales aligning with the gold standard:  ['M', 'ENTION', 'the', 'sh', 'ad', 'flag', 'the', 'is', 'flag']\n",
            "\n",
            "MENTION MENTION 10 employees + ?how many customers = ? need verify?\n",
            "Rationales aligning with the gold standard:  ['M', 'ENTION', 'M', 'ENTION']\n",
            "\n",
            "MENTION MENTION worth checking this out from MENTION on the flag itself. URL\n",
            "Rationales aligning with the gold standard:  ['M', 'ENTION', 'ENTION', 'checking', 'out', 'M', 'ENTION', 'the', 'flag', 'itself', 'URL']\n",
            "\n",
            "MENTION MENTION that flag is a shahadah flag. bandana on suspect says \"at your service, o muhammad\" URL\n",
            "Rationales aligning with the gold standard:  ['M', 'M', 'ENTION', 'flag', 'is', 'a', 'sh', 'ah', 'ad', 'ah', 'flag', 'suspect', 'says', 'at', 'your', 'service', 'hammad', 'URL']\n",
            "\n",
            "MENTION MENTION nm - bloody sends electric waves to girls for physical relationships despite having own wife, extrema characterless\n",
            "Rationales aligning with the gold standard:  ['M', 'ENTION', 'M', 'ENTION', 'bloody', 'sends', 'electric', 'girls', 'despite', 'having', 'ext', 're', 'character', 'less']\n",
            "\n",
            "MENTION MENTION islamic isn't a language\n",
            "Rationales aligning with the gold standard:  ['M', 'ENTION', 'is', 'lam', 'ic', 'a']\n",
            "\n",
            "MENTION MENTION cnn badly needs to employ reporters who can read. why not say as it is, that it's the islamic flag with shahada on it?\n",
            "Rationales aligning with the gold standard:  ['M', 'ENTION', 'c', 'nn', 'badly', 'needs', 'to', 'employ', 'reporters', 'who', 'can', 'why', 'not', 'say', 'it', 'is', 'that', 'it', 'lam', 'ic', 'flag', 'with', 'sh', 'ah', 'on', 'it']\n",
            "\n",
            "MENTION MENTION breaking?? it's been happening for 3 hours now. sheesh.\n",
            "Rationales aligning with the gold standard:  ['M', 'ENTION', 'breaking', 'been', 'happening', 'for']\n",
            "\n",
            "MENTION MENTION gee wonder why no one has a gun. oh that's right. australia bans citizens from having guns.\n",
            "Rationales aligning with the gold standard:  ['M', 'M', 'ENTION', 'g', 'ee', 'wonder', 'why', 'one', 'has', 'a', 'gun', 'oh', 'aust', 'ral', 'ia', 'bans', 'citizens', 'having', 'guns']\n",
            "\n",
            "MENTION MENTION #breaking ? its 5 hours into the #sydneysiege how is that breaking?\n",
            "Rationales aligning with the gold standard:  ['M', 'ENTION', 'ENTION', 'breaking', 'its', 'hours', 'into', 'the', 'd', 'neys', 'iege']\n",
            "\n",
            "MENTION MENTION where did he get the gun ?no muslim should allowed to carry gun hving gun or buy a gun.\n",
            "Rationales aligning with the gold standard:  ['M', 'ENTION', 'did', 'get', 'the', 'no', 'mus', 'lim', 'allowed', 'to', 'carry', 'gun', 'ving', 'gun', 'buy']\n",
            "\n",
            "MENTION MENTION hang those stupid hostage takers once they have been arrested! stupid dog eating bloody muslims!\n",
            "Rationales aligning with the gold standard:  ['M', 'ENTION', 'M', 'ENTION', 'those', 'stupid', 't', 'once', 'have', 'been', 'stupid', 'dog', 'eating', 'mus', 'lim']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the summarisation input from the replies which show most alignment to the gold label. We use the full replies identified above concatenated with the claim text for the summariser."
      ],
      "metadata": {
        "id": "qFRbZVyCw8mX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess the summarisation input\n",
        "\n",
        "text = [dict_to_save2['source']]\n",
        "text.extend([x['text'] for x in dict_to_save2['replies'][gold_label]])\n",
        "text = ' '.join(text)\n",
        "text = preprocess_tweet(text)\n",
        "print('Input for Summarisation: ', text)"
      ],
      "metadata": {
        "id": "MxbkjJm7yuVC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c5fd258-cffd-4fdb-ff8c-242a704ffa52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input for Summarisation:  #breaking: flag w/ islamic writing held up to window of #sydney cafe. police say up to 50 hostages. #australia pm convenes security team. MENTION MENTION it's the shahadah flag, not the isis flag. MENTION MENTION 10 employees + ?how many customers = ? need verify? MENTION MENTION worth checking this out from MENTION on the flag itself. URL MENTION MENTION that flag is a shahadah flag. bandana on suspect says \"at your service, o muhammad\" URL MENTION MENTION nm - bloody sends electric waves to girls for physical relationships despite having own wife, extrema characterless MENTION MENTION islamic isn't a language MENTION MENTION cnn badly needs to employ reporters who can read. why not say as it is, that it's the islamic flag with shahada on it? MENTION MENTION breaking?? it's been happening for 3 hours now. sheesh. MENTION MENTION gee wonder why no one has a gun. oh that's right. australia bans citizens from having guns. MENTION MENTION #breaking ? its 5 hours into the #sydneysiege how is that breaking? MENTION MENTION where did he get the gun ?no muslim should allowed to carry gun hving gun or buy a gun. MENTION MENTION hang those stupid hostage takers once they have been arrested! stupid dog eating bloody muslims!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(bart_ft(text,50,25))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyx8Rr38s7eg",
        "outputId": "bfb16a40-6d80-4d57-f09d-64606996104e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A flag with Islamic text written on it is held up to a window of a Sydney cafe, apparently holding hostages hostage. The majority believe that it is the Shahadah flag, not the isis flag.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The summary contains a justification for why the claim might be unreliable: the fact that it is a shahada flag and not an isis flag. However, the summary does not address the fact the rumour is no longer 'breaking news', nor that its number of reported hostages might be incorrect."
      ],
      "metadata": {
        "id": "77uJmA4488Il"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a different summary, it is also possible to shuffle the replies in the summarisation input according to several criteria: support score to the label, similarity to the claim, time stamp etc. Below is an implementation of sorting wrt to support scores."
      ],
      "metadata": {
        "id": "HjWn_jlDEdln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ordered_replies = []\n",
        "for reply in dict_to_save2['replies'][gold_label]:\n",
        "  for i,x in enumerate(reply['word_attr'][gold_label]):\n",
        "    if ']' in x[0] and i>1 and 'p' in reply['word_attr'][gold_label][i-1] and 'se' in reply['word_attr'][gold_label][i-2]:\n",
        "      start = i\n",
        "      break\n",
        "      \n",
        "  reply_score = sum([word[1] for word in reply['word_attr'][gold_label][start+1:]]) / sum([word[1] for word in reply['word_attr'][gold_label]])\n",
        "  ordered_replies.append((reply['text'],reply_score))\n",
        "\n",
        "ordered_replies.sort(key= lambda x: x[1],reverse=True)\n",
        "print(ordered_replies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF1wFeBUA1Ge",
        "outputId": "a56c0b3f-6329-44b3-fe65-a4aebfbb02ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(\"@willripleyCNN @CNN Gee wonder why no one has a gun. Oh that's right. Australia bans citizens from having guns.\", 2.4309663223162943), (\"@willripleyCNN @CNN CNN badly needs to employ reporters who can read. Why not say as it is, that it's the Islamic flag with Shahada on it?\", 0.944405505035455), ('@willripleyCNN @CNN That flag is a Shahadah flag. Bandana on suspect says \"At your service, O Muhammad\" http://t.co/4HRFDy4jwE', 0.6537335932273545), (\"@willripleyCNN @CNN Breaking?? It's been happening for 3 hours now. Sheesh.\", 0.2871692694077432), ('@willripleyCNN @CNN NM - bloody sends electric waves to girls for physical relationships despite having own wife, extrema characterless', 0.2250301049290929), ('@willripleyCNN @SteveHuff Worth checking this out from @smh on the flag itself. http://t.co/ORzzRkKuCx', 0.22466616719173943), (\"@willripleyCNN @CNN It's the Shahadah flag, not the ISIS flag.\", 0.22207233265118018), ('@willripleycnn @cnn #Breaking ?  Its 5 hours into the #SydneySiege How is that Breaking?', 0.15187843589718034), (\"@willripleyCNN @CNN Islamic isn't a language\", 0.13821172431846), ('@willripleyCNN @CNN hang those stupid hostage takers once they have been arrested! Stupid dog eating bloody Muslims!', 0.1284188307559893), ('@willripleyCNN @CNN where did he get the gun ?no Muslim should allowed to carry gun hving gun or buy a gun.', 0.12296848283494581), ('@willripleyCNN @CNN 10 employees + ?how many customers  = ? Need verify?', 0.03659833475193127)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = [dict_to_save2['source']]\n",
        "text.extend([x[0] for x in ordered_replies])\n",
        "text = ' '.join(text)\n",
        "text = preprocess_tweet(text)\n",
        "print('Input for Summarisation: ', text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcyPyo6ADkui",
        "outputId": "1f51a04d-0f3a-4295-bdca-20a805c6d9dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input for Summarisation:  #breaking: flag w/ islamic writing held up to window of #sydney cafe. police say up to 50 hostages. #australia pm convenes security team. MENTION MENTION gee wonder why no one has a gun. oh that's right. australia bans citizens from having guns. MENTION MENTION cnn badly needs to employ reporters who can read. why not say as it is, that it's the islamic flag with shahada on it? MENTION MENTION that flag is a shahadah flag. bandana on suspect says \"at your service, o muhammad\" URL MENTION MENTION breaking?? it's been happening for 3 hours now. sheesh. MENTION MENTION nm - bloody sends electric waves to girls for physical relationships despite having own wife, extrema characterless MENTION MENTION worth checking this out from MENTION on the flag itself. URL MENTION MENTION it's the shahadah flag, not the isis flag. MENTION MENTION #breaking ? its 5 hours into the #sydneysiege how is that breaking? MENTION MENTION islamic isn't a language MENTION MENTION hang those stupid hostage takers once they have been arrested! stupid dog eating bloody muslims! MENTION MENTION where did he get the gun ?no muslim should allowed to carry gun hving gun or buy a gun. MENTION MENTION 10 employees + ?how many customers = ? need verify?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(bart_ft(text,50,25))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUOctwlnEBnm",
        "outputId": "84e1986a-b8fc-4d73-a785-edad7132be49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A flag with Islamic text written on it is held up to a window of a Sydney cafe, apparently holding hostages hostage. The majority are shocked and confused about how this could possibly be happening.\n"
          ]
        }
      ]
    }
  ]
}